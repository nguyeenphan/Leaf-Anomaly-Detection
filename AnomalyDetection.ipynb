{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNZD9eGfAFo1"
      },
      "source": [
        "#Anomaly detection using Autoencoder (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ1ayI_qO8sd"
      },
      "source": [
        "## Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TyQhAKsmiz6",
        "outputId": "2e957afc-cbcd-4532-8cfe-ed11d0e05aed"
      },
      "outputs": [],
      "source": [
        "%pip install tsne-torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmzHapyn_Kco",
        "outputId": "c0198ac1-6355-4171-c746-067d403a679b"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebd8WzaDPf0G"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "LfgYQvxPNJDz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4fCu5kmP0ON"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdI55IUbBbo9"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VIBmvyoaBc8z"
      },
      "outputs": [],
      "source": [
        "cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xrAh771oBgrU"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmPuwhOTChID",
        "outputId": "7f46ad7c-943e-4bf6-b378-28d330c287db"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download vipoooool/new-plant-diseases-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w25CSrUCDCCY",
        "outputId": "f5c9e8b0-98e1-4834-dcf2-bffca92b04e3"
      },
      "outputs": [],
      "source": [
        "! unzip new-plant-diseases-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1Da-BpcBDyT",
        "outputId": "1d3d9bde-82c2-47ea-b193-4d31a1a82952"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW245JlZQgfe"
      },
      "source": [
        "## ِ Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "dq3xKA7ZIo1q",
        "outputId": "4c3d0311-3fa8-457a-d21e-046d9abbc91d"
      },
      "outputs": [],
      "source": [
        "img = Image.open('/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/grape-only-dataset/train/Grape___Black_rot/0b9d95bb-51c7-40f1-8a4b-f9838becb418___FAM_B.Rot 0493.JPG')\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Đọc ảnh gốc\n",
        "img = Image.open('/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/grape-only-dataset/train/Grape___Esca_(Black_Measles)/eb4b029a-c930-444b-ae7f-337085696357___FAM_B.Msls 3962.JPG')\n",
        "\n",
        "# Hàm CLAHE\n",
        "def apply_clahe(img_pil):\n",
        "    img = np.array(img_pil)\n",
        "    img_yuv = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    img_yuv[:,:,0] = clahe.apply(img_yuv[:,:,0])\n",
        "    img_clahe = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
        "    return Image.fromarray(img_clahe)\n",
        "\n",
        "# Hàm Gamma Correction\n",
        "def apply_gamma(img_pil, gamma=1.5):\n",
        "    img = np.array(img_pil) / 255\n",
        "    img_gamma = np.power(img, gamma)\n",
        "    img_gamma = np.uint8(img_gamma * 255)\n",
        "    return Image.fromarray(img_gamma)\n",
        "\n",
        "# Áp dụng CLAHE và Gamma Correction\n",
        "img_clahe = apply_clahe(img)\n",
        "img_gamma = apply_gamma(img_clahe, gamma=1.5)\n",
        "\n",
        "# Hiển thị ảnh before & after\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Before (Original)')\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('After (CLAHE + Gamma)')\n",
        "plt.imshow(img_gamma)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBmY1_X0O0rG"
      },
      "source": [
        "## Building train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "yHTumL5Irali"
      },
      "outputs": [],
      "source": [
        "# train_path = \"/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/grape-only-dataset/train\"\n",
        "\n",
        "train_path = \"/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "QtCj3Jj-LQeR"
      },
      "outputs": [],
      "source": [
        "def get_label(name):\n",
        "  label = 0\n",
        "  if bool(re.match('Grape___E.+', name)):\n",
        "    label = 1\n",
        "  elif bool(re.match('Grape___L.+', name)):\n",
        "    label = 2\n",
        "  elif bool(re.match('Grape___h.+', name)):\n",
        "    label = 3\n",
        "  return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfzL6jhKzSuu",
        "outputId": "4aca2a0d-dd13-4483-b87c-f84460ce6508"
      },
      "outputs": [],
      "source": [
        "convert_tensor = transforms.ToTensor()\n",
        "train_data = []\n",
        "for root, dirs, files in os.walk(train_path):\n",
        "  class_name = root.split('/')[-1]\n",
        "  if bool(re.match('Grape.+', class_name)):\n",
        "    for file in files:\n",
        "      path = os.path.join(root, file)\n",
        "      img = Image.open(path)\n",
        "      tensor_img = convert_tensor(img)\n",
        "      tensor_img = tensor_img.to(device)\n",
        "      label = get_label(class_name)\n",
        "      train_data.append([tensor_img, label])\n",
        "\n",
        "print(len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiODZ_er8h6o",
        "outputId": "79f16870-53f6-4bf7-932d-30120d0c94da"
      },
      "outputs": [],
      "source": [
        "train_data[0][0].is_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "aW1fEZo40w8c"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset= train_data,\n",
        "    batch_size=16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# class LeafDataset(Dataset):\n",
        "#     def __init__(self, data):\n",
        "#         self.data = data\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.data[idx][0], self.data[idx][1]\n",
        "\n",
        "# # Tạo dataset và dataloader\n",
        "# train_dataset = LeafDataset(train_data)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VPYGx2r1Kl_"
      },
      "outputs": [],
      "source": [
        "# train_iter = iter(train_loader)\n",
        "# train_images, train_labels = train_iter.next()\n",
        "# print(train_images.shape, '  ', train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGbIH1l_1RgI"
      },
      "outputs": [],
      "source": [
        "# print(torch.min(train_images), torch.max(train_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmwzzwTB11Pi"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "gYyKMhJM105C"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Conv2d(3, 16, kernel_size=7, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, kernel_size=7, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, kernel_size=7, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 128, kernel_size=5)\n",
        "    )\n",
        "\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.ConvTranspose2d(128, 64, kernel_size=5),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(64, 32, kernel_size=7, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(32, 16, kernel_size=7, stride=2, padding=1, output_padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(16, 3, kernel_size=7, stride=2, padding=1, output_padding=1),\n",
        "        nn.Sigmoid() # As we saw that the input tensors are between 0 and 1 so we should use an activation function to map our values to that range.\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from pytorch_msssim import SSIM\n",
        "\n",
        "# class AnomalyLoss(nn.Module):\n",
        "#     def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):\n",
        "#         super().__init__()\n",
        "#         self.alpha = alpha  # Hệ số cho MSE\n",
        "#         self.beta = beta    # Hệ số cho SSIM\n",
        "#         self.gamma = gamma  # Hệ số cho L1 Loss\n",
        "#         self.ssim = SSIM(data_range=1.0, size_average=True, channel=3)\n",
        "\n",
        "#     def forward(self, y_pred, y_true):\n",
        "#         # MSE Loss\n",
        "#         mse = F.mse_loss(y_pred, y_true)\n",
        "\n",
        "#         # SSIM Loss (1 - SSIM vì SSIM càng cao càng tốt)\n",
        "#         ssim = 1 - self.ssim(y_pred, y_true)\n",
        "\n",
        "#         # L1 Loss\n",
        "#         l1 = F.l1_loss(y_pred, y_true)\n",
        "\n",
        "#         # Kết hợp các loss\n",
        "#         total_loss = self.alpha * mse + self.beta * ssim + self.gamma * l1\n",
        "\n",
        "#         return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from piq import ssim\n",
        "from torchvision.models import vgg16\n",
        "\n",
        "class AnomalyLoss2(nn.Module):\n",
        "    def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.contrastive_loss = nn.CosineEmbeddingLoss()\n",
        "\n",
        "    def forward(self, y_pred, y_true, labels):\n",
        "        ssim_loss = 1 - ssim(y_pred, y_true, data_range=1.0)\n",
        "        \n",
        "        perceptual_loss = self.perceptual_loss(y_pred, y_true)\n",
        "        \n",
        "        #kl_divergence = self.kl_divergence(y_pred, y_true)\n",
        "        \n",
        "        contrastive_loss = self.contrastive_loss(y_pred, y_true, labels)\n",
        "        \n",
        "        total_loss = self.alpha * ssim_loss + self.beta * perceptual_loss + contrastive_loss\n",
        "        \n",
        "        return total_loss\n",
        "    \n",
        "    def perceptual_loss(self, y_pred, y_true):\n",
        "        # Trích xuất đặc trưng từ VGG16\n",
        "        y_pred_features = self.vgg(y_pred)\n",
        "        y_true_features = self.vgg(y_true)\n",
        "        # Tính toán MSE giữa các đặc trưng\n",
        "        return F.mse_loss(y_pred_features, y_true_features)\n",
        "\n",
        "    def kl_divergence(self, y_pred, y_true):\n",
        "        # Tính toán KL Divergence\n",
        "        y_pred_log_softmax = F.log_softmax(y_pred, dim=1)\n",
        "        y_true_softmax = F.softmax(y_true, dim=1)\n",
        "        return F.kl_div(y_pred_log_softmax, y_true_softmax, reduction='batchmean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "obxEz5893As5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class CustomLoss(nn.Module):\n",
        "#     def forward(self, y_pred, y_true):\n",
        "#         mse = F.mse_loss(y_pred, y_true)\n",
        "#         bce = F.binary_cross_entropy(y_pred, y_true)\n",
        "#         return mse + bce\n",
        "    \n",
        "# Sử dụng loss function\n",
        "criterion = AnomalyLoss2().to(device)\n",
        "model = Autoencoder().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(img.min().item(), img.max().item())   # nên thấy 0.0  1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# State_dict của model là một Python dict, với key là tên của layer và value là parameter của layer đó, \n",
        "# bao gồm weight và bias. Bên cạnh model, optimizer (torch.optim) cũng có state_dict, có chứa những thông tin về optimizer’s state, \n",
        "# cũng như các hyperparameter đi cùng.\n",
        "\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "print (\"\\n\")\n",
        "\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var in optimizer.state_dict():\n",
        "    print(var, \"\\t\", optimizer.state_dict()[var])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ckpt_path = '/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/checkpoint.pth'\n",
        "start_epoch = 0\n",
        "if os.path.exists(ckpt_path):\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    model.load_state_dict(ckpt['model_state_dict'])\n",
        "    optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
        "    start_epoch = ckpt['epoch'] + 1\n",
        "    print(f'\\nLoaded checkpoint at epoch {start_epoch}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lưu state_dict vào model \n",
        "torch.save(model.state_dict(), '/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/checkpoint.pth')\n",
        "# tải state_dict từ file\n",
        "state_dict = torch.load('/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/checkpoint.pth')\n",
        "# áp dụng state_dict vào model\n",
        "model.load_state_dict(state_dict)\n",
        "# save all model\n",
        "torch.save(model, '/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/model.pth')\n",
        "# load all model\n",
        "model = torch.load('/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "917tkyFTioNa",
        "outputId": "9e6abb4b-c5af-41f7-b28f-c4a61acb1323"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "  for epoch in range(1000): # 1000 epochs\n",
        "    for (img, _) in train_loader:\n",
        "      recon = model(img)\n",
        "      loss = criterion(recon, img)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')\n",
        "    # outputs.append((epoch, img, recon))\n",
        "    torch.save({\n",
        "      'epoch': epoch,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'loss': loss,\n",
        "    }, '/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/checkpoint.pth')\n",
        "      \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load checkpoint\n",
        "checkpoint = torch.load('/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/checkpoint.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKuktJItz6Yk"
      },
      "source": [
        "## Building test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "aTS7sZtTz9BH"
      },
      "outputs": [],
      "source": [
        "test_path = \"/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/grape-only-dataset/test/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsnhp78m0Hlu",
        "outputId": "b4a0a89c-d59d-49eb-f639-d0adf2463c68"
      },
      "outputs": [],
      "source": [
        "convert_tensor = transforms.ToTensor()\n",
        "test_data = []\n",
        "test_label = []\n",
        "for root, dirs, files in os.walk(test_path):\n",
        "    for file in files:\n",
        "      path = os.path.join(root, file)\n",
        "      img = Image.open(path)\n",
        "      tensor_img = convert_tensor(img)\n",
        "      tensor_img = tensor_img.to(device)\n",
        "      test_data.append([tensor_img, 4])\n",
        "      test_label.append('Anomaly')\n",
        "\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "9UHa1kb2cQBy"
      },
      "outputs": [],
      "source": [
        "test_data = test_data[:28]\n",
        "test_label = test_label[:28]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EBv_hgTQHrh"
      },
      "source": [
        "adding un-anomaly data to test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "jqj1A4CEQSsP"
      },
      "outputs": [],
      "source": [
        "val_path = '/Users/nguyenphan/Developer/Leaf-Anomaly-Detection/grape-only-dataset/valid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhK1L9lqQQAD",
        "outputId": "239e17a6-4a8a-4055-9bf5-eadfbdb8bedd"
      },
      "outputs": [],
      "source": [
        "count = [0 for i in range(4)]\n",
        "\n",
        "for root, dirs, files in os.walk(val_path):\n",
        "  class_name = root.split('/')[-1]\n",
        "  if bool(re.match('Grape.+', class_name)):\n",
        "    for file in files:\n",
        "      label = get_label(class_name)\n",
        "      count[label] += 1\n",
        "      if count[label] >= 18:\n",
        "        break\n",
        "      path = os.path.join(root, file)\n",
        "      img = Image.open(path)\n",
        "      tensor_img = convert_tensor(img)\n",
        "      tensor_img = tensor_img.to(device)\n",
        "      test_data.append([tensor_img, label])\n",
        "      test_label.append(label)\n",
        "\n",
        "\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx3UZ_KPS-BG",
        "outputId": "d3c14a50-cae4-4253-9e8b-6545f5c59df5"
      },
      "outputs": [],
      "source": [
        "test_data[0][0].is_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "sd2rVS5xV9SO"
      },
      "outputs": [],
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset= test_data,\n",
        "    batch_size=8,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdtNAO_SVXXy"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "NarU64K3KL9D"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rit27X5EVZkS",
        "outputId": "2614ac81-7909-48b8-e5c8-7ad03e485e57"
      },
      "outputs": [],
      "source": [
        "encodes = []\n",
        "\n",
        "for (img, _) in test_loader:\n",
        "  code = model.encoder(img)\n",
        "  encodes.append(torch.tensor(code, device = 'cpu'))\n",
        "  \n",
        "len(encodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t70spIhBlL5f",
        "outputId": "3c3acce5-2fde-4386-d069-c0a114ee4ed9"
      },
      "outputs": [],
      "source": [
        "[t.shape for t in encodes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUGC6LwiimeH",
        "outputId": "d247344b-3786-4ee5-f0bc-de68ef62a9ab"
      },
      "outputs": [],
      "source": [
        "y = []\n",
        "tsne = TSNE(perplexity=5)\n",
        "for t in encodes:\n",
        "  x = t.reshape(8, -1)\n",
        "  embd = tsne.fit_transform(x)\n",
        "  y.append(embd)\n",
        "\n",
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zpwAdABXIk0",
        "outputId": "9c29ce5c-ed78-445c-a178-c85ea960b116"
      },
      "outputs": [],
      "source": [
        "y[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRLzuF9YbG7n",
        "outputId": "01ab3069-9588-41c5-b5d4-63746c89097b"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "for i in range(len(y)):\n",
        "  for j in y[i]:\n",
        "    x.append(j)\n",
        "\n",
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZXnlTNrgnQH"
      },
      "outputs": [],
      "source": [
        "# ttt = np.array(x)\n",
        "# list(map(lambda i : i[0], x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "qmMf5k0caqsL",
        "outputId": "7becb397-fc88-4b6e-b9e5-fcd61309f88c"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "# sns.scatterplot(list(map(lambda i : i[0], x)), list(map(lambda i : i[1], x)), hue=test_label)\n",
        "\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "sns.scatterplot(x = list(map(lambda i : i[1], x)), y = list(map(lambda i : i[0], x)), hue=test_label)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SQ1ayI_qO8sd",
        "ebd8WzaDPf0G",
        "a4fCu5kmP0ON",
        "oW245JlZQgfe",
        "IBmY1_X0O0rG",
        "bmwzzwTB11Pi",
        "zKuktJItz6Yk",
        "MdtNAO_SVXXy"
      ],
      "name": "AnomalyDetection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
